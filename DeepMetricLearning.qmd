---
title: "Deep metric learning"
subtitle: "conceitos, aplica칞칫es e algumas contribui칞칫es"
author: Heitor S. Ramos <br> <a href="mailto:heitor@dcc.ufmg.br">heitor@dcc.ufmg.br</a>
# date: 03/08/2022 
# abstract-title: 
format: 
  revealjs: 
    code-fold: true 
    execute: 
      enabled: true
    echo: true
    jupyter: python3
    slide-number: true
    theme: default
    controls: true
    progress: true
    smaller: true
    # scrollable: true
    chalkboard:
      buttons: true
      chalk-width: 1
      theme: whiteboard
    preview-links: auto
    logo:  common/logos.png
    include-in-header:
    - text: |
        <style>
        .reveal .slide-logo {
          max-height: unset;
          height: 100px;
        }
        </style>
    style: common/style.css
    footer: <https://www.dcc.ufmg.br/~ramosh/>
# search: true
# resources:
#   - aula06.pdf
---

## Artificial Intelligence
Artificial intelligence (sometimes referred to by the acronym AI) is the science that studies the modeling of human-like intelligence exhibited by machines or software.

## Artificial Intelligence

![](figs/IA.png)

## Artificial Intelligence (Deep Learning Book)

![](figs/deep_learning-IA.png){#ia fig-align="center"}

## Classification
<!-- :::{.columns}

:::{.column width="50%"} -->
a subcategory of supervised learning where a function maps the input to an output (discrete label) based on examples of input-output pairs.

<!-- :::

:::{.column width="50%"} -->

![](figs/dog.png){#dog fig-align="center"}

<!-- :::
 
::: -->
 
## Classification

![](figs/laranja_maca.png){#laranja fig-align="center"}

## Feature


- A feature is a characteristic that describes an object. 

- Any attribute of an object can be treated as a feature, whether it is a number, text, date, boolean, etc

![](figs/features.png){#features fig-align="center"}

## Features and Classification

![](figs/features_classification.png){#features_class fig-align="center"}
 

## Supervised Learning

is a machine learning task that involves mapping inputs to outputs based on examples of input-output pairs.

![](figs/supervised.png){#supervised fig-align="center"}



## What if?

:::{.callout-important}
Our model learn the features?
:::

![](figs/deep-learning-model.png){#deeplearningmodel fig-align="center"}

## We want more than representation learning

![](figs/metric_learning.png)

## Different notions of similarity
 

![](figs/different_similarities.png){#similaries fig-align="center" width="80%"}

## Metric Space

Is a non-empty set together with a notion of distance between its elements. The distance is measured by a function called **metric** or distance **function**.


## Formally, a metric space is

an ordered pair $(洧,洧녬)$, where $洧$ is a set and $d$ is a metric on $洧$, i.e., a function $d: M\times M \rightarrow \mathbb R$, satisfying for all points $x,y \in M$

1. The distance from a point to itself is zero: $洧녬(洧논,洧논)=0$
2. (positivity) the distance between two points is always positive: if $洧논\ne 洧녽$ then $洧녬(洧논,洧녽)>0$
3. (Symmetry) the distance from $洧논$ to $洧녽$ is always the same as the distance from $洧녽$ to $洧논$: $洧녬(洧논,洧녽)=洧녬(洧녽,洧논)$
4. The triangle innequality holds: $洧녬(洧논,洧녾)\leq 洧녬(洧논,洧녽)+洧녬(洧녽,洧녾)$

## Metric examples

![](figs/metric_examples.png){#metrics fig-align="center" width="50%"}

## Distance notion

:::{.panel-tabset}

### What is extreme?
![](figs/pressao2.png){#pressao fig-align="center" width="50%"}


<!-- ## Distance notion -->

### Not Euclidean

![](figs/distancia_pressao2.png){#pressao2 fig-align="center" width="50%"}

<!-- ## Equidistant points -->
### Equidistant

![](figs/distancia_centro.png){#equidistant fig-align="center" width="50%"}

<!-- ## Equidistant points -->

### Equidistant 2

![](figs/elipse.png){#equidistant2 fig-align="center" width="50%"}

<!-- ## Equidistant points -->

### Equidistant 3

![](figs/distancias.png){#equidistant3 fig-align="center" width="50%"}

:::

## What distance are we talking about?

:::{.incremental}
:::{.callout-important}
- Mahalanobis
:::

- $$D(\boldsymbol x, \boldsymbol y) = \sqrt{(\boldsymbol x-\boldsymbol y)^\top \Sigma^{-1} (\boldsymbol x - \boldsymbol y)}$$
:::
## A little  linear algebra

- Remember that $\Sigma$ is a **semi**-positive matrix
- We can rearrange $\Sigma^{-1} = W^\top W$
- and rearrange the Mahalanobis distance as $$D(\boldsymbol x, \boldsymbol y) = \Vert W\boldsymbol x- W \boldsymbol y\Vert_2$$

![](figs/transformacaoLinear.png){#linear fig-align="center"}

## Metric Learning main goal

- Learn semantic relations between data points

- Ideia: Learn a mapping function that:
  - Semantic relation $\rightarrow$ (Pseudo) Metric distances

![](figs/dml_goal.png){#goal fig-align="center" width="60%"}

## In a nutshell

- Step 1 - Choose a parameterized embedding function $\Psi(\cdot)$

- Step 2 - Pick a distance measure $\Delta$ for the embedding space, e.g. $\Delta(\Psi(x, y)) \rightarrow$ Euclidean distance

- Step 3 - Define data $D$ and similarity rules:
  - $S = \{(x, y) \mid x, y \text{ are similar}\}$

  - $D = \{(x, y) \mid x, y \text{ are dissimilar}\}$

  - $T = \{(x, y, z) \mid x  \text{ is more similar to }  y \text{ than to }z\}$

## In a nutshell

![](figs/schemaDM.png){#schema fig-align="center" width="90%"}


## Deep Metric Learning

![](figs/arrange1.png){#arrange fig-align="center" width="90%"}


## Deep Metric Learning

![](figs/arrange2.png){#arrange2 fig-align="center" width="90%"}

## Deep Metric Learning

![](figs/arrange3.png){#arrange3 fig-align="center" width="90%"}

## Deep Metric Learning

![](figs/arrange3.png){#arrange4 fig-align="center" width="90%"}

## Deep Metric Learning

![](figs/arrange5.png){#arrange5 fig-align="center" width="100%"}

## Deep Metric Learning

![](figs/arrange6.png){#arrange6 fig-align="center" width="100%"}

## Our approach

![SMELL](figs/smell.png){#smell fig-align="center" width="100%"}

## SMELL

- SMELL tends to approximate the objects in the S-Space around their respective markers as well as re-position the markers according to vectors position.

:::{.panel-tabset}

### S-space
![](figs/smell_markers.png){#smell_markers fig-align="center" width="80%"}

### S-space (Traning)
![](figs/smell_traning.png){#smell_training fig-align="center" width="70%"}

### Inference

![](figs/smell_inference.png){#smell_inference fig-align="center" width="40%"}

### Latent Space

![](figs/smell_optimal1.png){#smell_optimal1 fig-align="center" width="60%"}

### OLS

![](figs/smell_optimal2.png){#smell_optimal2 fig-align="center" width="80%"}  
